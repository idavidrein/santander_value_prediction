{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root Mean Squared Log Error\n",
    "#Ensure all positive values in input arrays\n",
    "def rmsle(truth, predicted):\n",
    "    return np.sqrt(np.mean((np.log1p(np.absolute(predicted))-np.log1p(truth))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add features/preprocessing\n",
    "def prepare(data_orig):\n",
    "    \n",
    "    #PCA dimensionality reduction\n",
    "#     pca = PCA(n_components = 100)\n",
    "#     data = pd.DataFrame(pca.fit_transform(data_orig))\n",
    "    data = pd.DataFrame()\n",
    "    #feature engineering\n",
    "    data['mean'] = data_orig.mean(axis=1)\n",
    "    data['std'] = data_orig.std(axis=1)\n",
    "    data['min'] = data_orig.min(axis=1)\n",
    "    data['max'] = data_orig.max(axis=1)\n",
    "    \n",
    "    # Number of diferent values in a row.\n",
    "    data['number_of_different'] = data_orig.nunique(axis=1)\n",
    "    \n",
    "    # Number of non zero values (e.g. transaction count)\n",
    "    data['non_zero_count'] = data_orig.fillna(0).astype(bool).sum(axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_df = pd.read_csv('../input/train.csv')\n",
    "y_train = train_df.pop('target')\n",
    "iiii = train_df.pop('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns only with zeros\n",
    "train_df = train_df.loc[:, (train_df != 0).any(axis = 0)]\n",
    "\n",
    "#add features/preprocessing\n",
    "X_train = prepare(train_df).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "model.fit(X_train[:3000], y_train[:3000], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7704018371986483"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_train[3000:])\n",
    "rmsle(y_train[3000:], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create, fit, and evaluate model\n",
    "forest = RandomForestRegressor(n_estimators = 100)\n",
    "scores = np.sqrt(-cross_val_score(forest, X_train, y_train, cv = 5, \n",
    "                                  scoring = 'neg_mean_squared_log_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.62185737194\n",
      "[ 1.56127572  1.6685679   1.54884223  1.64102238  1.68957863]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')\n",
    "ids = test_df.pop('ID')\n",
    "\n",
    "with open(\"../predictions/predictions.csv\", \"w\", newline = '') as writeCSV:\n",
    "    writer = csv.writer(writeCSV)\n",
    "    writer.writerow([\"ID\",\"target\"])\n",
    "    kTest = prepare(test_df).values\n",
    "    output = forest.predict(kTest)\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        writer.writerow([ids[i], output[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
